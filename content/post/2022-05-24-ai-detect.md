---
layout: post
title:  "batchsize, epochs说明"
date: 2022-05-24 10:54:16
categories: [ai]
tags: [ai]
excerpt_separator: <!--more-->
---
batchsize, epochs说明
<!--more-->

batchsize, epochs是机器学习中超参数，需要根据经验进行设置。

## batchsize

每个batch 中： 训练样本的数量。

* 批量梯度下降
    batchsize=训练集的大小, 全部。类似算数平均。
    收敛性最好，但由于每次计算都会使用全部数据进行计算，时间和内存花费比较大。

* 随机梯度下降
    batchsize= 1。类似移动平均。
    收敛性最差，剧烈波动。

* 小批量梯度下降
    1 < batchsize < 训练集的大小。类似加权移动平均。

## epochs

定义了学习算法在整个训练数据集中的工作次数。epochs不是越大越好。
epochs越多，拟合状态会从不拟合->拟合->过拟合。

训练次数越多，对学习的数据集识别率会越来越高，但是对数据集以外的基本不识别，这时就是过拟合状态。需要减少训练次数。